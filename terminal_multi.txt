2020-05-27 10:06:32.170570: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-05-27 10:06:32.290988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:b1:00.0
totalMemory: 10.92GiB freeMemory: 9.92GiB
2020-05-27 10:06:32.291021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-05-27 10:06:32.684587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-27 10:06:32.684629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-05-27 10:06:32.684636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-05-27 10:06:32.684730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3353 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:b1:00.0, compute capability: 6.1)
2020-05-27 10:06:34.551259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-05-27 10:06:34.551309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-27 10:06:34.551315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-05-27 10:06:34.551320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-05-27 10:06:34.551393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3353 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:b1:00.0, compute capability: 6.1)
Current Experiment: multi_label_user



Execute the following in a terminal:
tensorboard --logdir=/srv/workspace/research/extra_experiment_results/multi_label_user/2020-05-27_10-06-34
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #1 Loss: 1.3952 My_loss: 0.0000 accuracy: 0.5295
validation Loss : 1.2576 validation accuracy: 0.5593
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #2 Loss: 1.2914 My_loss: 0.0000 accuracy: 0.5306
validation Loss : 1.2452 validation accuracy: 0.5895
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #3 Loss: 1.2563 My_loss: 0.0000 accuracy: 0.5306
validation Loss : 1.2639 validation accuracy: 0.5582
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #4 Loss: 1.2410 My_loss: 0.0000 accuracy: 0.5273
validation Loss : 1.2413 validation accuracy: 0.5368
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #5 Loss: 1.2323 My_loss: 0.0000 accuracy: 0.5241
validation Loss : 1.2247 validation accuracy: 0.5576
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #6 Loss: 1.2264 My_loss: 0.0000 accuracy: 0.5201
validation Loss : 1.2312 validation accuracy: 0.5355
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #7 Loss: 1.2194 My_loss: 0.0000 accuracy: 0.5221
validation Loss : 1.2276 validation accuracy: 0.5480
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #8 Loss: 1.2148 My_loss: 0.0000 accuracy: 0.5188
validation Loss : 1.2186 validation accuracy: 0.5287
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #9 Loss: 1.2083 My_loss: 0.0000 accuracy: 0.5218
validation Loss : 1.2154 validation accuracy: 0.5196
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #10 Loss: 1.2018 My_loss: 0.0000 accuracy: 0.5270
validation Loss : 1.2118 validation accuracy: 0.5720
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #11 Loss: 1.1992 My_loss: 0.0000 accuracy: 0.5234
validation Loss : 1.2358 validation accuracy: 0.5569
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #12 Loss: 1.1932 My_loss: 0.0000 accuracy: 0.5270
validation Loss : 1.2050 validation accuracy: 0.5885
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #13 Loss: 1.1874 My_loss: 0.0000 accuracy: 0.5355
validation Loss : 1.2028 validation accuracy: 0.5990
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #14 Loss: 1.1794 My_loss: 0.0000 accuracy: 0.5414
validation Loss : 1.1954 validation accuracy: 0.5952
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #15 Loss: 1.1745 My_loss: 0.0000 accuracy: 0.5406
validation Loss : 1.1936 validation accuracy: 0.5893
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #16 Loss: 1.1674 My_loss: 0.0000 accuracy: 0.5450
validation Loss : 1.1901 validation accuracy: 0.6178
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #17 Loss: 1.1636 My_loss: 0.0000 accuracy: 0.5512
validation Loss : 1.1889 validation accuracy: 0.5792
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #18 Loss: 1.1568 My_loss: 0.0000 accuracy: 0.5568
validation Loss : 1.1802 validation accuracy: 0.6040
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #19 Loss: 1.1510 My_loss: 0.0000 accuracy: 0.5593
validation Loss : 1.1843 validation accuracy: 0.6250
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #20 Loss: 1.1468 My_loss: 0.0000 accuracy: 0.5626
validation Loss : 1.1802 validation accuracy: 0.6033
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #21 Loss: 1.1402 My_loss: 0.0000 accuracy: 0.5672
validation Loss : 1.1807 validation accuracy: 0.5935
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #22 Loss: 1.1367 My_loss: 0.0000 accuracy: 0.5693
validation Loss : 1.1804 validation accuracy: 0.6197
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #23 Loss: 1.1307 My_loss: 0.0000 accuracy: 0.5736
validation Loss : 1.1750 validation accuracy: 0.6089
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #24 Loss: 1.1292 My_loss: 0.0000 accuracy: 0.5784
validation Loss : 1.1795 validation accuracy: 0.5882
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #25 Loss: 1.1240 My_loss: 0.0000 accuracy: 0.5792
validation Loss : 1.1836 validation accuracy: 0.5960
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #26 Loss: 1.1214 My_loss: 0.0000 accuracy: 0.5805
validation Loss : 1.1771 validation accuracy: 0.5978
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #27 Loss: 1.1177 My_loss: 0.0000 accuracy: 0.5817
validation Loss : 1.1813 validation accuracy: 0.6307
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #28 Loss: 1.1149 My_loss: 0.0000 accuracy: 0.5847
validation Loss : 1.1763 validation accuracy: 0.6240
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #29 Loss: 1.1124 My_loss: 0.0000 accuracy: 0.5861
validation Loss : 1.1731 validation accuracy: 0.6150
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #30 Loss: 1.1077 My_loss: 0.0000 accuracy: 0.5902
validation Loss : 1.1779 validation accuracy: 0.6158
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #31 Loss: 1.1050 My_loss: 0.0000 accuracy: 0.5949
validation Loss : 1.1848 validation accuracy: 0.6162
0
100
200
300
400
500
600
700
800
900
1000
1100
1200/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
multi_label_embed_deeper.py:154: UserWarning: Boolean Series key will be reindexed to match DataFrame index.
  labels = global_labels[global_labels.song_id == song_id][global_labels.user_id == user_id]

1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #32 Loss: 1.1025 My_loss: 0.0000 accuracy: 0.5949
validation Loss : 1.1766 validation accuracy: 0.6282
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #33 Loss: 1.1019 My_loss: 0.0000 accuracy: 0.5968
validation Loss : 1.1756 validation accuracy: 0.6128
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #34 Loss: 1.0988 My_loss: 0.0000 accuracy: 0.5975
validation Loss : 1.1751 validation accuracy: 0.6141
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #35 Loss: 1.0958 My_loss: 0.0000 accuracy: 0.5988
validation Loss : 1.1876 validation accuracy: 0.6235
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #36 Loss: 1.0939 My_loss: 0.0000 accuracy: 0.6003
validation Loss : 1.1925 validation accuracy: 0.6133
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #37 Loss: 1.0930 My_loss: 0.0000 accuracy: 0.6021
validation Loss : 1.1835 validation accuracy: 0.6263
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #38 Loss: 1.0926 My_loss: 0.0000 accuracy: 0.6029
validation Loss : 1.1789 validation accuracy: 0.6289
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #39 Loss: 1.0895 My_loss: 0.0000 accuracy: 0.6044
validation Loss : 1.1796 validation accuracy: 0.6185
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #40 Loss: 1.0864 My_loss: 0.0000 accuracy: 0.6043
validation Loss : 1.1859 validation accuracy: 0.6318
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #41 Loss: 1.0869 My_loss: 0.0000 accuracy: 0.6072
validation Loss : 1.1875 validation accuracy: 0.6268
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #42 Loss: 1.0846 My_loss: 0.0000 accuracy: 0.6076
validation Loss : 1.1849 validation accuracy: 0.6324
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #43 Loss: 1.0842 My_loss: 0.0000 accuracy: 0.6072
validation Loss : 1.1853 validation accuracy: 0.6263
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #44 Loss: 1.0826 My_loss: 0.0000 accuracy: 0.6087
validation Loss : 1.1841 validation accuracy: 0.6305
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #45 Loss: 1.0817 My_loss: 0.0000 accuracy: 0.6087
validation Loss : 1.1904 validation accuracy: 0.6278
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #46 Loss: 1.0824 My_loss: 0.0000 accuracy: 0.6090
validation Loss : 1.1827 validation accuracy: 0.6312
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #47 Loss: 1.0819 My_loss: 0.0000 accuracy: 0.6098
validation Loss : 1.1895 validation accuracy: 0.6313
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #48 Loss: 1.0793 My_loss: 0.0000 accuracy: 0.6105
validation Loss : 1.1840 validation accuracy: 0.6298
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #49 Loss: 1.0784 My_loss: 0.0000 accuracy: 0.6122
validation Loss : 1.1854 validation accuracy: 0.6269
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #50 Loss: 1.0775 My_loss: 0.0000 accuracy: 0.6105
validation Loss : 1.1828 validation accuracy: 0.6345
No improvement found in a last 10 epochs, stopping optimization.
Last iteration model saved in path: /srv/workspace/research/extra_experiment_results/multi_label_user/2020-05-27_10-06-34/last_epoch.ckpt
Model with best validation restored before testing.
Traceback (most recent call last):
  File "multi_label_embed_deeper.py", line 750, in <module>
    main()
  File "multi_label_embed_deeper.py", line 736, in main
    train_phase: False})
ValueError: could not broadcast input array from shape (32,10) into shape (10)
