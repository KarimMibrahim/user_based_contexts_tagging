{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "Gz_pUe-sZrsA",
    "outputId": "e6545645-18b8-4848-b7c1-a84c1324f87f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sn\n",
    "from sklearn.metrics import cohen_kappa_score,f1_score,accuracy_score, precision_score, recall_score, classification_report, roc_auc_score, \\\n",
    "    hamming_loss\n",
    "from itertools import compress\n",
    "import os \n",
    "LABELS_LIST = ['car', 'gym', 'happy', 'night', 'relax',\n",
    "    'running', 'sad', 'summer', 'work', 'workout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n1Xs-n0k-fZS"
   },
   "outputs": [],
   "source": [
    "def get_user_results(model_output, groundtruth,LABELS_LIST,selected_labels):  \n",
    "    model_output_rounded = np.round(model_output)\n",
    "    model_output_rounded = np.clip(model_output_rounded, 0, 1)\n",
    "    \n",
    "    # Create a dataframe where we keep all the evaluations, starting by prediction accuracy\n",
    "    accuracies_perclass = sum(model_output_rounded == groundtruth) / len(groundtruth)\n",
    "    results_df = pd.DataFrame(columns=LABELS_LIST)\n",
    "    results_df.index.astype(str, copy=False)\n",
    "    percentage_of_positives_perclass = sum(groundtruth) / len(groundtruth)\n",
    "    results_df.loc[0] = percentage_of_positives_perclass\n",
    "    results_df.loc[1] = accuracies_perclass\n",
    "    results_df.index = ['Ratio of positive samples', 'Model accuracy']\n",
    "\n",
    "    # Get true negative ratio\n",
    "    true_negative_ratio_perclass = sum((model_output_rounded == groundtruth)\n",
    "                                       * (groundtruth == 0)) / (len(groundtruth) - sum(groundtruth))\n",
    "    results_df.loc[2] = true_negative_ratio_perclass\n",
    "    \n",
    "    # compute additional metrics (AUC,f1,recall,precision)\n",
    "    precision_perlabel = precision_score(groundtruth, model_output_rounded, average=None)\n",
    "    recall_perlabel = recall_score(groundtruth, model_output_rounded, average=None)\n",
    "    f1_perlabel = f1_score(groundtruth, model_output_rounded, average=None)\n",
    "    results_df = results_df.append(\n",
    "        pd.DataFrame([recall_perlabel, precision_perlabel, f1_perlabel], columns=LABELS_LIST))\n",
    "    results_df.index = ['Ratio of positive samples', 'Model accuracy', \n",
    "                        \"True negative ratio\", \"Recall\", \"Precision\", \"f1-score\"]\n",
    "    results_df = results_df[selected_labels.index[selected_labels]] \n",
    "    results_df['average'] = results_df.mean(numeric_only=True, axis=1)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x-7nKQ1k1WgW"
   },
   "source": [
    "## user embeddings results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YrZYLrMUZzMs"
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_PATh = \"/srv/workspace/research/user_based_contexts_tagging/experiments_results/user_embeddings_active/2020-04-28_11-59-23/\"\n",
    "test_ground_truth = pd.read_csv(\"/srv/workspace/research/user_based_contexts_tagging/GroundTruth/test_active_clipped.csv\")\n",
    "test_groundtruth_from_model = np.loadtxt(EXPERIMENT_PATh + \"test_ground_truth_classes.txt\",delimiter=',')\n",
    "user_ids = np.loadtxt(EXPERIMENT_PATh + \"user_ids.txt\",delimiter=',')\n",
    "track_ids = np.loadtxt(EXPERIMENT_PATh + \"tracks_ids.txt\",delimiter=',')\n",
    "test_output = np.loadtxt(EXPERIMENT_PATh + \"predictions.out\",delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MoT1BBrajdwQ"
   },
   "outputs": [],
   "source": [
    "our_ground_truth = test_ground_truth.copy()\n",
    "our_ground_truth.song_id = track_ids\n",
    "our_ground_truth.user_id = user_ids\n",
    "our_ground_truth.iloc[:,2:] = test_groundtruth_from_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQZDQVOCjdiI"
   },
   "outputs": [],
   "source": [
    "our_predictions = test_ground_truth.copy()\n",
    "our_predictions.song_id = track_ids\n",
    "our_predictions.user_id = user_ids\n",
    "our_predictions.iloc[:,2:] = test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rGXBH9rqkkuN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  app.launch_new_instance()\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "all_users_results = pd.DataFrame(columns=['Ratio of positive samples', 'Model accuracy', \n",
    "                        \"True negative ratio\", \"Recall\", \"Precision\", \"f1-score\"])\n",
    "for user in our_ground_truth.user_id.unique():\n",
    "    user_truth = our_ground_truth[our_ground_truth.user_id == user]\n",
    "    user_preds = our_predictions[our_predictions.user_id == user]\n",
    "    active_labels = user_truth.sum() > 0\n",
    "    active_labels = active_labels[2:]\n",
    "    user_results = get_user_results(user_preds.values[:,2:],user_truth.values[:,2:],LABELS_LIST,active_labels)\n",
    "    user_results = user_results[\"average\"].T.values\n",
    "    all_users_results.loc[user] = user_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "LVrwR5V394FM",
    "outputId": "585fbdde-97e5-45a2-8d84-a066787d582d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratio of positive samples</th>\n",
       "      <th>Model accuracy</th>\n",
       "      <th>True negative ratio</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1399.000000</td>\n",
       "      <td>1399.000000</td>\n",
       "      <td>742.000000</td>\n",
       "      <td>1399.000000</td>\n",
       "      <td>1399.000000</td>\n",
       "      <td>1399.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.720785</td>\n",
       "      <td>0.614129</td>\n",
       "      <td>0.479885</td>\n",
       "      <td>0.661343</td>\n",
       "      <td>0.756574</td>\n",
       "      <td>0.661316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.270351</td>\n",
       "      <td>0.163249</td>\n",
       "      <td>0.198824</td>\n",
       "      <td>0.161700</td>\n",
       "      <td>0.251557</td>\n",
       "      <td>0.180526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.325942</td>\n",
       "      <td>0.569722</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.529186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.457738</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.783654</td>\n",
       "      <td>0.655749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.723544</td>\n",
       "      <td>0.633475</td>\n",
       "      <td>0.765924</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.807692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Ratio of positive samples  Model accuracy  True negative ratio  \\\n",
       "count                1399.000000     1399.000000           742.000000   \n",
       "mean                    0.720785        0.614129             0.479885   \n",
       "std                     0.270351        0.163249             0.198824   \n",
       "min                     0.176471        0.000000             0.000000   \n",
       "25%                     0.500000        0.500000             0.325942   \n",
       "50%                     0.551724        0.600000             0.457738   \n",
       "75%                     1.000000        0.723544             0.633475   \n",
       "max                     1.000000        1.000000             1.000000   \n",
       "\n",
       "            Recall    Precision     f1-score  \n",
       "count  1399.000000  1399.000000  1399.000000  \n",
       "mean      0.661343     0.756574     0.661316  \n",
       "std       0.161700     0.251557     0.180526  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%       0.569722     0.520833     0.529186  \n",
       "50%       0.675676     0.783654     0.655749  \n",
       "75%       0.765924     1.000000     0.807692  \n",
       "max       1.000000     1.000000     1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_users_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kQfFGA2xpBX4"
   },
   "outputs": [],
   "source": [
    "summarized = all_users_results.describe()\n",
    "summarized.to_csv(EXPERIMENT_PATh + \"user_based_results_summary.csv\")\n",
    "all_users_results.to_csv(EXPERIMENT_PATh + \"user_based_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZoNYFj87Lg5c"
   },
   "source": [
    "## Classic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eHhg87Tp737t"
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_PATh = \"/srv/workspace/research/user_based_contexts_tagging/experiments_results/classic_active/2020-04-28_12-29-52/\"\n",
    "test_ground_truth = pd.read_csv(\"/srv/workspace/research/user_based_contexts_tagging/GroundTruth/test_active_clipped.csv\")\n",
    "test_groundtruth_from_model = np.loadtxt(EXPERIMENT_PATh + \"test_ground_truth_classes.txt\",delimiter=',')\n",
    "user_ids = np.loadtxt(EXPERIMENT_PATh + \"user_ids.txt\",delimiter=',')\n",
    "track_ids = np.loadtxt(EXPERIMENT_PATh + \"tracks_ids.txt\",delimiter=',')\n",
    "test_output = np.loadtxt(EXPERIMENT_PATh + \"predictions.out\",delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kOTZOXXSMg4W"
   },
   "outputs": [],
   "source": [
    "our_ground_truth = test_ground_truth.copy()\n",
    "our_ground_truth.song_id = track_ids\n",
    "our_ground_truth.user_id = user_ids\n",
    "our_ground_truth.iloc[:,2:] = test_groundtruth_from_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pAlzbyBPMg4w"
   },
   "outputs": [],
   "source": [
    "our_predictions = test_ground_truth.copy()\n",
    "our_predictions.song_id = track_ids\n",
    "our_predictions.user_id = user_ids\n",
    "our_predictions.iloc[:,2:] = test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "qBy2ur9UMg49",
    "outputId": "ff950f03-b60f-4c03-b05d-240a579ebb3e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "all_users_results = pd.DataFrame(columns=['Ratio of positive samples', 'Model accuracy', \n",
    "                        \"True negative ratio\", \"Recall\", \"Precision\", \"f1-score\"])\n",
    "for user in our_ground_truth.user_id.unique():\n",
    "    user_truth = our_ground_truth[our_ground_truth.user_id == user]\n",
    "    user_preds = our_predictions[our_predictions.user_id == user]\n",
    "    active_labels = user_truth.sum() > 0\n",
    "    active_labels = active_labels[2:]\n",
    "    user_results = get_user_results(user_preds.values[:,2:],user_truth.values[:,2:],LABELS_LIST,active_labels)\n",
    "    user_results = user_results[\"average\"].T.values\n",
    "    all_users_results.loc[user] = user_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tZGwjQCt-iiW"
   },
   "outputs": [],
   "source": [
    "summarized = all_users_results.describe()\n",
    "summarized.to_csv(EXPERIMENT_PATh + \"user_based_results_summary.csv\")\n",
    "all_users_results.to_csv(EXPERIMENT_PATh + \"user_based_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratio of positive samples</th>\n",
       "      <th>Model accuracy</th>\n",
       "      <th>True negative ratio</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1399.000000</td>\n",
       "      <td>1399.000000</td>\n",
       "      <td>742.000000</td>\n",
       "      <td>1399.000000</td>\n",
       "      <td>1399.000000</td>\n",
       "      <td>1399.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.720785</td>\n",
       "      <td>0.645354</td>\n",
       "      <td>0.402104</td>\n",
       "      <td>0.732599</td>\n",
       "      <td>0.753268</td>\n",
       "      <td>0.688643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.270351</td>\n",
       "      <td>0.201706</td>\n",
       "      <td>0.220756</td>\n",
       "      <td>0.195541</td>\n",
       "      <td>0.251331</td>\n",
       "      <td>0.200503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.169405</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.232197</td>\n",
       "      <td>0.614949</td>\n",
       "      <td>0.520787</td>\n",
       "      <td>0.536118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.373857</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.763986</td>\n",
       "      <td>0.670409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.527604</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Ratio of positive samples  Model accuracy  True negative ratio  \\\n",
       "count                1399.000000     1399.000000           742.000000   \n",
       "mean                    0.720785        0.645354             0.402104   \n",
       "std                     0.270351        0.201706             0.220756   \n",
       "min                     0.176471        0.029412             0.000000   \n",
       "25%                     0.500000        0.500000             0.232197   \n",
       "50%                     0.551724        0.617647             0.373857   \n",
       "75%                     1.000000        0.793103             0.527604   \n",
       "max                     1.000000        1.000000             1.000000   \n",
       "\n",
       "            Recall    Precision     f1-score  \n",
       "count  1399.000000  1399.000000  1399.000000  \n",
       "mean      0.732599     0.753268     0.688643  \n",
       "std       0.195541     0.251331     0.200503  \n",
       "min       0.029412     0.169405     0.057143  \n",
       "25%       0.614949     0.520787     0.536118  \n",
       "50%       0.750000     0.763986     0.670409  \n",
       "75%       0.888889     1.000000     0.864932  \n",
       "max       1.000000     1.000000     1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_users_results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QmkNxk2PbiF0"
   },
   "source": [
    "## Deeper model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "liDTc2sLbkBe"
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_PATh = \"/srv/workspace/research/user_based_contexts_tagging/experiments_results/user_embeddings_deeper/2020-05-02_10-36-37/\"\n",
    "test_ground_truth = pd.read_csv(\"/srv/workspace/research/user_based_contexts_tagging/GroundTruth/test_active_clipped.csv\")\n",
    "user_ids = np.loadtxt(EXPERIMENT_PATh + \"user_ids.txt\",delimiter=',')\n",
    "track_ids = np.loadtxt(EXPERIMENT_PATh + \"tracks_ids.txt\",delimiter=',')\n",
    "\n",
    "EXPERIMENT_PATh = \"/srv/workspace/research/user_based_contexts_tagging/experiments_results/user_embeddings_deeper/2020-04-21_14-55-56/\"\n",
    "test_groundtruth_from_model = np.loadtxt(EXPERIMENT_PATh + \"test_ground_truth_classes.txt\",delimiter=',')\n",
    "test_output = np.loadtxt(EXPERIMENT_PATh + \"predictions.out\",delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MoT1BBrajdwQ"
   },
   "outputs": [],
   "source": [
    "our_ground_truth = test_ground_truth.copy()\n",
    "our_ground_truth.song_id = track_ids\n",
    "our_ground_truth.user_id = user_ids\n",
    "our_ground_truth.iloc[:,2:] = test_groundtruth_from_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQZDQVOCjdiI"
   },
   "outputs": [],
   "source": [
    "our_predictions = test_ground_truth.copy()\n",
    "our_predictions.song_id = track_ids\n",
    "our_predictions.user_id = user_ids\n",
    "our_predictions.iloc[:,2:] = test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rGXBH9rqkkuN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "all_users_results = pd.DataFrame(columns=['Ratio of positive samples', 'Model accuracy', \n",
    "                        \"True negative ratio\", \"Recall\", \"Precision\", \"f1-score\"])\n",
    "for idx,user in enumerate(our_ground_truth.user_id.unique()):\n",
    "    user_truth = our_ground_truth[our_ground_truth.user_id == user]\n",
    "    user_preds = our_predictions[our_predictions.user_id == user]\n",
    "    active_labels = user_truth.sum() > 0\n",
    "    active_labels = active_labels[2:]\n",
    "    user_results = get_user_results(user_preds.values[:,2:],user_truth.values[:,2:],LABELS_LIST,active_labels)\n",
    "    user_results = user_results[\"average\"].T.values\n",
    "    all_users_results.loc[user] = user_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "LVrwR5V394FM",
    "outputId": "585fbdde-97e5-45a2-8d84-a066787d582d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratio of positive samples</th>\n",
       "      <th>Model accuracy</th>\n",
       "      <th>True negative ratio</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1399.000000</td>\n",
       "      <td>1399.000000</td>\n",
       "      <td>1399.000000</td>\n",
       "      <td>1399.000000</td>\n",
       "      <td>1399.000000</td>\n",
       "      <td>1399.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.108349</td>\n",
       "      <td>0.371357</td>\n",
       "      <td>0.305543</td>\n",
       "      <td>0.852557</td>\n",
       "      <td>0.135864</td>\n",
       "      <td>0.225291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.008634</td>\n",
       "      <td>0.024451</td>\n",
       "      <td>0.026542</td>\n",
       "      <td>0.071424</td>\n",
       "      <td>0.016630</td>\n",
       "      <td>0.024222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.179302</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.089765</td>\n",
       "      <td>0.152934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.101818</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.292491</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.124682</td>\n",
       "      <td>0.209040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.105714</td>\n",
       "      <td>0.372414</td>\n",
       "      <td>0.307703</td>\n",
       "      <td>0.857540</td>\n",
       "      <td>0.134006</td>\n",
       "      <td>0.223810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.111396</td>\n",
       "      <td>0.386207</td>\n",
       "      <td>0.321634</td>\n",
       "      <td>0.906508</td>\n",
       "      <td>0.145146</td>\n",
       "      <td>0.239652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.152709</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.207683</td>\n",
       "      <td>0.316071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Ratio of positive samples  Model accuracy  True negative ratio  \\\n",
       "count                1399.000000     1399.000000          1399.000000   \n",
       "mean                    0.108349        0.371357             0.305543   \n",
       "std                     0.008634        0.024451             0.026542   \n",
       "min                     0.100000        0.275000             0.179302   \n",
       "25%                     0.101818        0.357143             0.292491   \n",
       "50%                     0.105714        0.372414             0.307703   \n",
       "75%                     0.111396        0.386207             0.321634   \n",
       "max                     0.152709        0.482759             0.408323   \n",
       "\n",
       "            Recall    Precision     f1-score  \n",
       "count  1399.000000  1399.000000  1399.000000  \n",
       "mean      0.852557     0.135864     0.225291  \n",
       "std       0.071424     0.016630     0.024222  \n",
       "min       0.600000     0.089765     0.152934  \n",
       "25%       0.808333     0.124682     0.209040  \n",
       "50%       0.857540     0.134006     0.223810  \n",
       "75%       0.906508     0.145146     0.239652  \n",
       "max       1.000000     0.207683     0.316071  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_users_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kQfFGA2xpBX4"
   },
   "outputs": [],
   "source": [
    "summarized = all_users_results.describe()\n",
    "summarized.to_csv(EXPERIMENT_PATh + \"user_based_results_summary.csv\")\n",
    "all_users_results.to_csv(EXPERIMENT_PATh + \"user_based_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "liDTc2sLbkBe"
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_PATh = \"/srv/workspace/research/user_based_contexts_tagging/experiments_results/user_embeddings_deeper/2020-05-02_10-36-37/\"\n",
    "test_ground_truth = pd.read_csv(\"/srv/workspace/research/user_based_contexts_tagging/GroundTruth/test_active_clipped.csv\")\n",
    "user_ids = np.loadtxt(EXPERIMENT_PATh + \"user_ids.txt\",delimiter=',')\n",
    "track_ids = np.loadtxt(EXPERIMENT_PATh + \"tracks_ids.txt\",delimiter=',')\n",
    "\n",
    "EXPERIMENT_PATh = \"/srv/workspace/research/user_based_contexts_tagging/experiments_results/user_embeddings_progressive/2020-05-03_11-56-57/\"\n",
    "test_groundtruth_from_model = np.loadtxt(EXPERIMENT_PATh + \"test_ground_truth_classes.txt\",delimiter=',')\n",
    "test_output = np.loadtxt(EXPERIMENT_PATh + \"predictions.out\",delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MoT1BBrajdwQ"
   },
   "outputs": [],
   "source": [
    "our_ground_truth = test_ground_truth.copy()\n",
    "our_ground_truth.song_id = track_ids\n",
    "our_ground_truth.user_id = user_ids\n",
    "our_ground_truth.iloc[:,2:] = test_groundtruth_from_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQZDQVOCjdiI"
   },
   "outputs": [],
   "source": [
    "our_predictions = test_ground_truth.copy()\n",
    "our_predictions.song_id = track_ids\n",
    "our_predictions.user_id = user_ids\n",
    "our_predictions.iloc[:,2:] = test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rGXBH9rqkkuN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "all_users_results = pd.DataFrame(columns=['Ratio of positive samples', 'Model accuracy', \n",
    "                        \"True negative ratio\", \"Recall\", \"Precision\", \"f1-score\"])\n",
    "for idx,user in enumerate(our_ground_truth.user_id.unique()):\n",
    "    user_truth = our_ground_truth[our_ground_truth.user_id == user]\n",
    "    user_preds = our_predictions[our_predictions.user_id == user]\n",
    "    active_labels = user_truth.sum() > 0\n",
    "    active_labels = active_labels[2:]\n",
    "    user_results = get_user_results(user_preds.values[:,2:],user_truth.values[:,2:],LABELS_LIST,active_labels)\n",
    "    user_results = user_results[\"average\"].T.values\n",
    "    all_users_results.loc[user] = user_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "LVrwR5V394FM",
    "outputId": "585fbdde-97e5-45a2-8d84-a066787d582d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratio of positive samples</th>\n",
       "      <th>Model accuracy</th>\n",
       "      <th>True negative ratio</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1399.000000</td>\n",
       "      <td>1399.000000</td>\n",
       "      <td>1399.000000</td>\n",
       "      <td>1399.000000</td>\n",
       "      <td>1399.000000</td>\n",
       "      <td>1399.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.108349</td>\n",
       "      <td>0.108642</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.999342</td>\n",
       "      <td>0.108332</td>\n",
       "      <td>0.190013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.008634</td>\n",
       "      <td>0.008669</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.008620</td>\n",
       "      <td>0.013267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.096875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.096976</td>\n",
       "      <td>0.162497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.101818</td>\n",
       "      <td>0.102273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.101786</td>\n",
       "      <td>0.179523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.105714</td>\n",
       "      <td>0.106061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.105769</td>\n",
       "      <td>0.185997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.111396</td>\n",
       "      <td>0.114035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111525</td>\n",
       "      <td>0.197034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.152709</td>\n",
       "      <td>0.147783</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.147783</td>\n",
       "      <td>0.250891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Ratio of positive samples  Model accuracy  True negative ratio  \\\n",
       "count                1399.000000     1399.000000          1399.000000   \n",
       "mean                    0.108349        0.108642             0.000362   \n",
       "std                     0.008634        0.008669             0.001094   \n",
       "min                     0.100000        0.096875             0.000000   \n",
       "25%                     0.101818        0.102273             0.000000   \n",
       "50%                     0.105714        0.106061             0.000000   \n",
       "75%                     0.111396        0.114035             0.000000   \n",
       "max                     0.152709        0.147783             0.008621   \n",
       "\n",
       "            Recall    Precision     f1-score  \n",
       "count  1399.000000  1399.000000  1399.000000  \n",
       "mean      0.999342     0.108332     0.190013  \n",
       "std       0.006787     0.008620     0.013267  \n",
       "min       0.857143     0.096976     0.162497  \n",
       "25%       1.000000     0.101786     0.179523  \n",
       "50%       1.000000     0.105769     0.185997  \n",
       "75%       1.000000     0.111525     0.197034  \n",
       "max       1.000000     0.147783     0.250891  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_users_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kQfFGA2xpBX4"
   },
   "outputs": [],
   "source": [
    "summarized = all_users_results.describe()\n",
    "summarized.to_csv(EXPERIMENT_PATh + \"user_based_results_summary.csv\")\n",
    "all_users_results.to_csv(EXPERIMENT_PATh + \"user_based_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "egU0BLJ4KjCn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "user_resultsAnalysis",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
