2020-06-29 13:35:57.633864: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2020-06-29 13:35:57.753217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:b1:00.0
totalMemory: 10.92GiB freeMemory: 9.91GiB
2020-06-29 13:35:57.753248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-06-29 13:35:58.158112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-29 13:35:58.158156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-06-29 13:35:58.158162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-06-29 13:35:58.158248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3353 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:b1:00.0, compute capability: 6.1)
/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From only_embeds.py:581: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.
Instructions for updating:
Use the `axis` argument instead
WARNING:tensorflow:From only_embeds.py:593: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

2020-06-29 13:35:59.794759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-06-29 13:35:59.794810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-29 13:35:59.794816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-06-29 13:35:59.794821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-06-29 13:35:59.794896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3353 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:b1:00.0, compute capability: 6.1)
Current Experiment: only_embeds



Execute the following in a terminal:
tensorboard --logdir=/srv/workspace/research/extra_experiment_results/only_embeds/2020-06-29_13-35-59
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #1 Loss: 28.4196 My_loss: 0.0000 accuracy: 0.8227
validation Loss : 22.8707 validation accuracy: 0.8328
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #2 Loss: 24.2986 My_loss: 0.0000 accuracy: 0.8270
validation Loss : 22.2222 validation accuracy: 0.8374
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #3 Loss: 22.9826 My_loss: 0.0000 accuracy: 0.8299
validation Loss : 22.0231 validation accuracy: 0.8406
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #4 Loss: 22.4681 My_loss: 0.0000 accuracy: 0.8324
validation Loss : 21.8724 validation accuracy: 0.8433
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #5 Loss: 22.1736 My_loss: 0.0000 accuracy: 0.8349
validation Loss : 21.7528 validation accuracy: 0.8440
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #6 Loss: 22.0179 My_loss: 0.0000 accuracy: 0.8366
validation Loss : 21.6529 validation accuracy: 0.8450
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #7 Loss: 21.9122 My_loss: 0.0000 accuracy: 0.8376
validation Loss : 21.5985 validation accuracy: 0.8451
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #8 Loss: 21.8296 My_loss: 0.0000 accuracy: 0.8387
validation Loss : 21.5352 validation accuracy: 0.8458
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #9 Loss: 21.7473 My_loss: 0.0000 accuracy: 0.8390
validation Loss : 21.5094 validation accuracy: 0.8455
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #10 Loss: 21.6655 My_loss: 0.0000 accuracy: 0.8402
validation Loss : 21.4528 validation accuracy: 0.8459
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #11 Loss: 21.6265 My_loss: 0.0000 accuracy: 0.8406
validation Loss : 21.3980 validation accuracy: 0.8467
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #12 Loss: 21.5755 My_loss: 0.0000 accuracy: 0.8411
validation Loss : 21.3460 validation accuracy: 0.8464
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #13 Loss: 21.5350 My_loss: 0.0000 accuracy: 0.8413
validation Loss : 21.3263 validation accuracy: 0.8470
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #14 Loss: 21.4720 My_loss: 0.0000 accuracy: 0.8417
validation Loss : 21.2955 validation accuracy: 0.8470
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #15 Loss: 21.4327 My_loss: 0.0000 accuracy: 0.8421
validation Loss : 21.2636 validation accuracy: 0.8474
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #16 Loss: 21.3983 My_loss: 0.0000 accuracy: 0.8425
validation Loss : 21.2638 validation accuracy: 0.8473
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #17 Loss: 21.3809 My_loss: 0.0000 accuracy: 0.8427
validation Loss : 21.2244 validation accuracy: 0.8481
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #18 Loss: 21.3488 My_loss: 0.0000 accuracy: 0.8428
validation Loss : 21.1623 validation accuracy: 0.8482
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #19 Loss: 21.3099 My_loss: 0.0000 accuracy: 0.8432
validation Loss : 21.1494 validation accuracy: 0.8484
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #20 Loss: 21.2828 My_loss: 0.0000 accuracy: 0.8436
validation Loss : 21.1392 validation accuracy: 0.8483
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #21 Loss: 21.2575 My_loss: 0.0000 accuracy: 0.8441
validation Loss : 21.1085 validation accuracy: 0.8488
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #22 Loss: 21.2255 My_loss: 0.0000 accuracy: 0.8444
validation Loss : 21.1137 validation accuracy: 0.8486
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #23 Loss: 21.1765 My_loss: 0.0000 accuracy: 0.8444
validation Loss : 21.0778 validation accuracy: 0.8487
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #24 Loss: 21.1474 My_loss: 0.0000 accuracy: 0.8446
validation Loss : 21.0276 validation accuracy: 0.8491
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #25 Loss: 21.1393 My_loss: 0.0000 accuracy: 0.8447
validation Loss : 21.0391 validation accuracy: 0.8491
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #26 Loss: 21.1114 My_loss: 0.0000 accuracy: 0.8448
validation Loss : 21.0197 validation accuracy: 0.8496
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #27 Loss: 21.0767 My_loss: 0.0000 accuracy: 0.8454
validation Loss : 20.9860 validation accuracy: 0.8500
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #28 Loss: 21.0571 My_loss: 0.0000 accuracy: 0.8456
validation Loss : 21.0230 validation accuracy: 0.8494
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #29 Loss: 21.0285 My_loss: 0.0000 accuracy: 0.8457
validation Loss : 20.9700 validation accuracy: 0.8500
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #30 Loss: 21.0059 My_loss: 0.0000 accuracy: 0.8457
validation Loss : 20.9356 validation accuracy: 0.8503
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #31 Loss: 20.9887 My_loss: 0.0000 accuracy: 0.8460
validation Loss : 20.9402 validation accuracy: 0.8503
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #32 Loss: 20.9763 My_loss: 0.0000 accuracy: 0.8463
validation Loss : 20.9292 validation accuracy: 0.8510
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #33 Loss: 20.9691 My_loss: 0.0000 accuracy: 0.8459
validation Loss : 20.9020 validation accuracy: 0.8504
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #34 Loss: 20.9399 My_loss: 0.0000 accuracy: 0.8464
validation Loss : 20.9190 validation accuracy: 0.8505
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #35 Loss: 20.9235 My_loss: 0.0000 accuracy: 0.8464
validation Loss : 20.9016 validation accuracy: 0.8507
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #36 Loss: 20.9238 My_loss: 0.0000 accuracy: 0.8461
validation Loss : 20.8869 validation accuracy: 0.8508
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #37 Loss: 20.8937 My_loss: 0.0000 accuracy: 0.8471
validation Loss : 20.8518 validation accuracy: 0.8506
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #38 Loss: 20.8876 My_loss: 0.0000 accuracy: 0.8468
validation Loss : 20.8554 validation accuracy: 0.8514
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #39 Loss: 20.8533 My_loss: 0.0000 accuracy: 0.8470
validation Loss : 20.8327 validation accuracy: 0.8509
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #40 Loss: 20.8229 My_loss: 0.0000 accuracy: 0.8471
validation Loss : 20.8557 validation accuracy: 0.8507
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #41 Loss: 20.8441 My_loss: 0.0000 accuracy: 0.8469
validation Loss : 20.8345 validation accuracy: 0.8511
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #42 Loss: 20.8311 My_loss: 0.0000 accuracy: 0.8476
validation Loss : 20.8209 validation accuracy: 0.8514
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #43 Loss: 20.8406 My_loss: 0.0000 accuracy: 0.8471
validation Loss : 20.7846 validation accuracy: 0.8512
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #44 Loss: 20.8147 My_loss: 0.0000 accuracy: 0.8474
validation Loss : 20.8003 validation accuracy: 0.8518
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #45 Loss: 20.7801 My_loss: 0.0000 accuracy: 0.8474
validation Loss : 20.7946 validation accuracy: 0.8512
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #46 Loss: 20.8004 My_loss: 0.0000 accuracy: 0.8476
validation Loss : 20.8054 validation accuracy: 0.8508
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #47 Loss: 20.7981 My_loss: 0.0000 accuracy: 0.8473
validation Loss : 20.8038 validation accuracy: 0.8515
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #48 Loss: 20.7477 My_loss: 0.0000 accuracy: 0.8476
validation Loss : 20.7790 validation accuracy: 0.8515
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #49 Loss: 20.7560 My_loss: 0.0000 accuracy: 0.8478
validation Loss : 20.7561 validation accuracy: 0.8517
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #50 Loss: 20.7562 My_loss: 0.0000 accuracy: 0.8481
validation Loss : 20.7811 validation accuracy: 0.8523
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #51 Loss: 20.7549 My_loss: 0.0000 accuracy: 0.8480
validation Loss : 20.7623 validation accuracy: 0.8520
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #52 Loss: 20.7384 My_loss: 0.0000 accuracy: 0.8481
validation Loss : 20.7764 validation accuracy: 0.8518
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #53 Loss: 20.7307 My_loss: 0.0000 accuracy: 0.8482
validation Loss : 20.7754 validation accuracy: 0.8518
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #54 Loss: 20.7291 My_loss: 0.0000 accuracy: 0.8481
validation Loss : 20.7527 validation accuracy: 0.8521
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #55 Loss: 20.6993 My_loss: 0.0000 accuracy: 0.8483
validation Loss : 20.7187 validation accuracy: 0.8518
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #56 Loss: 20.6879 My_loss: 0.0000 accuracy: 0.8484
validation Loss : 20.7399 validation accuracy: 0.8521
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #57 Loss: 20.7098 My_loss: 0.0000 accuracy: 0.8486
validation Loss : 20.7304 validation accuracy: 0.8525
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #58 Loss: 20.6908 My_loss: 0.0000 accuracy: 0.8483
validation Loss : 20.7313 validation accuracy: 0.8522
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #59 Loss: 20.6721 My_loss: 0.0000 accuracy: 0.8485
validation Loss : 20.7530 validation accuracy: 0.8523
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #60 Loss: 20.6702 My_loss: 0.0000 accuracy: 0.8485
validation Loss : 20.7454 validation accuracy: 0.8528
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #61 Loss: 20.6579 My_loss: 0.0000 accuracy: 0.8486
validation Loss : 20.7010 validation accuracy: 0.8522
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #62 Loss: 20.6746 My_loss: 0.0000 accuracy: 0.8486
validation Loss : 20.7156 validation accuracy: 0.8522
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #63 Loss: 20.6620 My_loss: 0.0000 accuracy: 0.8486
validation Loss : 20.7142 validation accuracy: 0.8530
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #64 Loss: 20.6491 My_loss: 0.0000 accuracy: 0.8486
validation Loss : 20.7124 validation accuracy: 0.8525
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #65 Loss: 20.6415 My_loss: 0.0000 accuracy: 0.8484
validation Loss : 20.7194 validation accuracy: 0.8524
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #66 Loss: 20.6391 My_loss: 0.0000 accuracy: 0.8490
validation Loss : 20.7142 validation accuracy: 0.8526
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #67 Loss: 20.6502 My_loss: 0.0000 accuracy: 0.8488
validation Loss : 20.6807 validation accuracy: 0.8524
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #68 Loss: 20.6517 My_loss: 0.0000 accuracy: 0.8487
validation Loss : 20.7055 validation accuracy: 0.8530
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #69 Loss: 20.6355 My_loss: 0.0000 accuracy: 0.8488
validation Loss : 20.7057 validation accuracy: 0.8530
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #70 Loss: 20.6113 My_loss: 0.0000 accuracy: 0.8491
validation Loss : 20.6856 validation accuracy: 0.8527
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #71 Loss: 20.5959 My_loss: 0.0000 accuracy: 0.8488
validation Loss : 20.7196 validation accuracy: 0.8523
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #72 Loss: 20.6105 My_loss: 0.0000 accuracy: 0.8492
validation Loss : 20.6940 validation accuracy: 0.8528
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #73 Loss: 20.6270 My_loss: 0.0000 accuracy: 0.8489
validation Loss : 20.6847 validation accuracy: 0.8528
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #74 Loss: 20.5893 My_loss: 0.0000 accuracy: 0.8493
validation Loss : 20.6776 validation accuracy: 0.8526
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #75 Loss: 20.6321 My_loss: 0.0000 accuracy: 0.8491
validation Loss : 20.6880 validation accuracy: 0.8529
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #76 Loss: 20.6124 My_loss: 0.0000 accuracy: 0.8486
validation Loss : 20.6753 validation accuracy: 0.8529
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #77 Loss: 20.6259 My_loss: 0.0000 accuracy: 0.8489
validation Loss : 20.6997 validation accuracy: 0.8518
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #78 Loss: 20.6050 My_loss: 0.0000 accuracy: 0.8490
validation Loss : 20.6824 validation accuracy: 0.8527
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #79 Loss: 20.5776 My_loss: 0.0000 accuracy: 0.8494
validation Loss : 20.6784 validation accuracy: 0.8529
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #80 Loss: 20.6060 My_loss: 0.0000 accuracy: 0.8489
validation Loss : 20.6605 validation accuracy: 0.8527
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #81 Loss: 20.5789 My_loss: 0.0000 accuracy: 0.8494
validation Loss : 20.6730 validation accuracy: 0.8532
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #82 Loss: 20.5945 My_loss: 0.0000 accuracy: 0.8493
validation Loss : 20.6702 validation accuracy: 0.8526
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #83 Loss: 20.6017 My_loss: 0.0000 accuracy: 0.8492
validation Loss : 20.6963 validation accuracy: 0.8528
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #84 Loss: 20.6031 My_loss: 0.0000 accuracy: 0.8491
validation Loss : 20.6892 validation accuracy: 0.8529
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #85 Loss: 20.5747 My_loss: 0.0000 accuracy: 0.8494
validation Loss : 20.6787 validation accuracy: 0.8532
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #86 Loss: 20.5867 My_loss: 0.0000 accuracy: 0.8493
validation Loss : 20.6493 validation accuracy: 0.8533
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #87 Loss: 20.6158 My_loss: 0.0000 accuracy: 0.8490
validation Loss : 20.6672 validation accuracy: 0.8532
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #88 Loss: 20.5914 My_loss: 0.0000 accuracy: 0.8492
validation Loss : 20.6687 validation accuracy: 0.8530
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #89 Loss: 20.5804 My_loss: 0.0000 accuracy: 0.8492
validation Loss : 20.6820 validation accuracy: 0.8530
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #90 Loss: 20.6004 My_loss: 0.0000 accuracy: 0.8491
validation Loss : 20.6836 validation accuracy: 0.8526
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #91 Loss: 20.5706 My_loss: 0.0000 accuracy: 0.8496
validation Loss : 20.6642 validation accuracy: 0.8531
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #92 Loss: 20.5566 My_loss: 0.0000 accuracy: 0.8495
validation Loss : 20.6370 validation accuracy: 0.8524
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #93 Loss: 20.5939 My_loss: 0.0000 accuracy: 0.8494
validation Loss : 20.6706 validation accuracy: 0.8531
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #94 Loss: 20.5924 My_loss: 0.0000 accuracy: 0.8494
validation Loss : 20.6530 validation accuracy: 0.8532
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700only_embeds.py:154: UserWarning: Boolean Series key will be reindexed to match DataFrame index.
  labels = global_labels[global_labels.song_id == song_id][global_labels.user_id == user_id]

1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #95 Loss: 20.5828 My_loss: 0.0000 accuracy: 0.8492
validation Loss : 20.6708 validation accuracy: 0.8533
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #96 Loss: 20.5787 My_loss: 0.0000 accuracy: 0.8495
validation Loss : 20.6866 validation accuracy: 0.8530
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #97 Loss: 20.5461 My_loss: 0.0000 accuracy: 0.8493
validation Loss : 20.6746 validation accuracy: 0.8532
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #98 Loss: 20.6037 My_loss: 0.0000 accuracy: 0.8493
validation Loss : 20.6361 validation accuracy: 0.8526
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #99 Loss: 20.5651 My_loss: 0.0000 accuracy: 0.8497
validation Loss : 20.6617 validation accuracy: 0.8532
0
100
200
300
400
500
600
700
800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
2000
2100
2200
2300
2400
2500
2600
2700
2800
2900
3000
3100
Epoch #100 Loss: 20.5651 My_loss: 0.0000 accuracy: 0.8497
validation Loss : 20.6639 validation accuracy: 0.8532
Last iteration model saved in path: /srv/workspace/research/extra_experiment_results/only_embeds/2020-06-29_13-35-59/last_epoch.ckpt
Model with best validation restored before testing.
Exact match accuracy is: 26.71361502347418%
Macro Area Under the Curve (AUC) is: 0.7135212070080463
saving prediction to disk
